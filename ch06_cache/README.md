# cache

## キャッシュメモリ
CPU の演算に比べてメモリ I/O は遥かに遅いため，
メモリ I/O がボトルネックになることが多い．
CPU に内蔵されているメモリよりもアクセス速度が早い領域をキャッシュメモリと呼ぶ．
キャッシュメモリへのアクセスはメモリへのアクセスよりも数倍速い．
キャッシュメモリは階層構造になっており， CPU に近いほど小容量で高速担になっている．
メモリ内容をキャッシュする単位をキャッシュラインと呼び，
CPU ごとにその大きさが決まっている．

```cache.c``` を以下のようにビルドし， ```run_program.sh``` を実行すると
アクセスするキャッシュ領域によってループ1回あたりの時間に大きく差があることが確認できる．

``` gcc -O3 cache.c ```

キャッシュによって高速化されるのは物理メモリへのアクセスであり，
仮想アドレスを物理アドレスに変換する処理は高速化されない．
この問題を解決するために CPU には Translation Lookaside Buffer (TLB)
というキャッシュと同様に高速にアクセス可能な領域があり，
仮想アドレスから物理アドレスへの変換表が保持されている．

## ページキャッシュ
メモリ内容をキャッシュメモリにキャッシュするように，
ストレージ上のファイルをメモリにキャッシュする仕組みがページキャッシュである．
キャッシュデータはページ単位で管理される．

プロセスがファイルデータを読みだす時は，プロセスのメモリにファイル内容を直接コピーするのではなく，
メモリ上のページキャッシュ領域にコピーしてからプロセスのメモリにコピーする．
ページキャッシュは全プロセス共有であるため，再度読みだすプロセスは別のプロセスでもよい．
書き込み時は，ページキャッシュに変更内容を記述し，後から所定のタイミングでストレージに反映する．

ページキャッシュ領域はメモリに空きがある限り際限なく確保されていく．
メモリ枯渇時には，カーネルによってページキャッシュが解放されていく．
この時，ダーティページが多い場合はストレージへの I/O が多発するため，
プログラムの性能が劣化する．

```read-twice.sh``` を実行することでページキャッシュによる I/O の高速化が確認できる．
プログラムの稼働集の統計情報を ```sar ``` コマンドで確認するとページキャッシュ関連の情報が確認できる．

## ハイパースレッド
キャッシュ等で頑張ったところで CPU の処理時間のほうが速いため結局は CPU 時間が空費されてしまう．
CPU を効率的に使用するためにレジスタなどの CPU の資源を分割し，
複数の論理 CPU として使用する仕組みをハイパースレッドと呼ぶ．
ハイパースレッドを使用したとしても性能が単純に２倍になるわけではない．